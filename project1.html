<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Project Title | Jasper Lee</title>
  <link rel="stylesheet" href="style.css?v=20240621" />
</head>
<body class="brain-theme project-detail">
  <canvas id="brain-canvas"></canvas>

  <header>
    <div class="nav-left">
      <h1 class="logo">Jasper Lee</h1>
      <nav>
        <a href="index.html#about">About</a>
        <a href="index.html#left-brain" class="active">Left Brain</a>
        <a href="index.html#right-brain">Right Brain</a>
        <a href="index.html#contact">Contact</a>
      </nav>
    </div>
    <!-- <a class="back-link" href="index.html#left-brain">← Back to Left Brain</a> -->
  </header>

  <main class="project-page">
    <section class="project-shell">
      <h2>Project Title</h2>
      <p class="project-tagline"> Redefine how humans interact with technology and the world around us.</p>

      <div class="project-section">
        <div class="project-media">
          <img src="hand.heic" alt="Prototype of the project" />
        </div>
        <div class="project-copy">
          <h3>Origin Story</h3>
          <p>
            While building a transforming tricopter drone, I learned that my grandmother had fallen down the stairs, 
            breaking her arm and unable to reach her phone for help. That moment made me think deeply about how we 
            could extend human capability—to manipulate and control objects beyond our physical reach, reducing the 
            need for direct contact and preventing harm.
            Many technologies tackle specific challenges—accessibility, exploration, search and rescue—but few aim to
            unify them into a single solution. I decided to start with one of humanity’s most powerful tools: the hand.
            My vision is an aerial bionic hand—a device that not only mirrors human dexterity but also extends our reach 
            into environments too dangerous or distant for us to access. With a simple extension of the arm and a curl of 
            the finger, we could take problems literally into our own hands—using mechanical precision and strength to act 
            safely at a distance. Whether it’s cutting a seatbelt to free a trapped passenger, delivering medical aid to 
            soldiers, retrieving a phone after a fall, or simply grabbing a cup of coffee across the room, this aerial 
            bionic hand brings the future of human-robot interaction closer to the everyday world.
          </p>
        </div>
      </div>

      <div class="project-section reverse">
        <div class="project-media">
          <!-- <img src="project-image-2.jpg" alt="In-progress build of the project" /> -->
        </div>
        <div class="project-copy">
          <h3>Engineering the Solution</h3>
          <p>
          I have broken down this projct into simple categories: hardware and software. 
            
            <br><br>
            Hardware: 
            <ul>
              <li>MCU/Radio Transmitter & Receiver: ESP32 </li>
              <li>Driver: ODrive for BLDC motors </li>
              <li>Finger Pulley Actuation: BLDC + planetary gear reduction for smooth control and high torque</li>
              <li>Center Thrust: Large flat pancake motors with high torque + ducted propeller as main center thrust force</li>
              <li>Angular Thrust: Micro motors + propellers to change the angle of the hand</li>
              <li>Sensors: EMG + flex sensors to determine the positioning and movement of the user's hand</li>
              <li>Material: CFRP (Carbon Fiber Reinforced Polymer) for low density + strength</li>
              <li>IMU: ICM-20948 for compactness + 9DOF + low power consumption</li>
            </ul>
            <br><br>

            Software:
            <pre><code>
              
              loop_fixed_2ms() { // 500 Hz
              imu_read();                               // ISR filled buffer
              quat = mahony_update(gyro, accel, mag);   // state estimation
              att_err = att_target - quat_to_euler(quat);
              rate_cmd = angle_pid(att_err) + feedforward;
              motor_cmds = mix(rate_cmd, thrust_target);
              actuators_write(motor_cmds);
            }
            
            loop_10ms() { // 100 Hz
              emg_feats = emg_process(raw_emg);
              cmd = gesture_map(emg_feats, mode);
              att_target = shape(cmd.attitude);         // LPF + slew limit
              thrust_target = shape(cmd.thrust);
              safety_check();
            }
            
            loop_25ms() { // 40 Hz
              if (pos_ctrl_enabled) {
                pos_err = pos_target - pos_estimate();
                att_target += pos_pid(pos_err);
              }
              telemetry_send();
            }
              
            </code></pre>
            
          </p>
          <ul>
            <li>Microcontrollers: Arduino Nano + ODrive</li>
            <li>Motors: Brushless DC with planetary gear reduction</li>
            <li>Control: Position + torque feedback with encoders</li>
          </ul>
        </div>
      </div>

      <div class="project-section">
        <div class="project-media">
          <img src="project-image-3.jpg" alt="Finished project in action" />
        </div>
        <div class="project-copy">
          <h3>Impact &amp; Next Steps</h3>
          <p>
            Share what you learned, how the prototype performed, and how you plan to iterate. Tie the story back to the
            user experience or mission and invite collaborators to reach out.
          </p>
        </div>
      </div>

      <div class="project-video">
        <h3>See It in Motion</h3>
        <div class="video-frame">
          <iframe
            src="https://www.youtube.com/embed/YOUR_VIDEO_ID"
            title="Project Video"
            frameborder="0"
            allowfullscreen
          ></iframe>
        </div>
      </div>
    </section>
  </main>

  <footer>
    <p>© 2025 Jasper Lee</p>
  </footer>

  <script>
    (function () {
      const desiredHighlight = 'left';

      function applyHighlight() {
        if (window.setBrainHighlight) {
          window.setBrainHighlight(desiredHighlight);
        } else {
          window.pendingBrainHighlight = desiredHighlight;
        }
      }

      if (document.readyState === 'complete' || document.readyState === 'interactive') {
        applyHighlight();
      } else {
        document.addEventListener('DOMContentLoaded', applyHighlight);
      }
    })();
  </script>
  <script src="brain.js?v=20240621" defer></script>
</body>
</html>
